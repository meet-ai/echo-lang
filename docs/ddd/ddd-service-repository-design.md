# DDD é¢†åŸŸæœåŠ¡å’Œä»“å‚¨è®¾è®¡ï¼šå‰ç«¯æ¨¡å—

## ğŸ¯ è®¾è®¡ç›®æ ‡

å°†parser.goä¸­çš„å¤æ‚é€»è¾‘æ‹†åˆ†ä¸ºèŒè´£å•ä¸€çš„é¢†åŸŸæœåŠ¡ï¼Œå®ç°ï¼š
- **èŒè´£åˆ†ç¦»**ï¼šæ¯ä¸ªæœåŠ¡è´Ÿè´£ä¸€ä¸ªå…·ä½“çš„åˆ†æé˜¶æ®µ
- **æ¥å£éš”ç¦»**ï¼šé€šè¿‡æ¥å£å®ç°ä¾èµ–å€’ç½®
- **å¯æµ‹è¯•æ€§**ï¼šæœåŠ¡å¯ç‹¬ç«‹æµ‹è¯•å’Œæ›¿æ¢
- **ä¸šåŠ¡è¡¨è¾¾**ï¼šæœåŠ¡å‘½ååæ˜ ä¸šåŠ¡æ„å›¾

## ğŸ› ï¸ é¢†åŸŸæœåŠ¡è®¾è®¡

### 1. è¯æ³•åˆ†ææœåŠ¡ï¼ˆLexical Analysis Serviceï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šå°†æºä»£ç è½¬æ¢ä¸ºTokenæµï¼Œå®ç°è¯æ³•åˆ†æã€‚

```go
// Tokenizer è¯æ³•åˆ†æå™¨æ¥å£
type Tokenizer interface {
    // Tokenize å°†æºä»£ç è½¬æ¢ä¸ºTokenåºåˆ—
    Tokenize(source SourceCode) ([]Token, error)
}

// SourceCode å€¼å¯¹è±¡ï¼šè¯æ³•åˆ†æçš„è¾“å…¥
type SourceCode struct {
    content  string
    filePath string
}

// SimpleTokenizer ç®€å•è¯æ³•åˆ†æå™¨å®ç°
type SimpleTokenizer struct{}

func (t *SimpleTokenizer) Tokenize(source SourceCode) ([]Token, error) {
    var tokens []Token
    lexer := NewLexer(source.content, source.filePath)

    for {
        token, err := lexer.NextToken()
        if err != nil {
            return nil, err
        }
        if token.Kind == EOF {
            break
        }
        tokens = append(tokens, token)
    }

    return tokens, nil
}

// ç§æœ‰é¢†åŸŸé€»è¾‘
func (t *SimpleTokenizer) isKeyword(word string) bool {
    keywords := []string{"func", "if", "else", "for", "while", "struct", "enum", "trait", "return"}
    for _, kw := range keywords {
        if word == kw {
            return true
        }
    }
    return false
}

func (t *SimpleTokenizer) isOperator(char byte) bool {
    operators := []byte{'+', '-', '*', '/', '=', '!', '<', '>', '&', '|', '^'}
    for _, op := range operators {
        if char == op {
            return true
        }
    }
    return false
}
```

**è®¾è®¡å†³ç­–**ï¼š
- **å•ä¸€èŒè´£**ï¼šåªè´Ÿè´£è¯æ³•åˆ†æï¼Œä¸æ¶‰åŠè¯­æ³•åˆ†æ
- **é”™è¯¯å¤„ç†**ï¼šè¯æ³•é”™è¯¯ç«‹å³è¿”å›ï¼Œä¸ç»§ç»­åˆ†æ
- **å¯æ‰©å±•æ€§**ï¼šæ˜“äºæ·»åŠ æ–°Tokenç±»å‹

### 2. è¯­æ³•åˆ†ææœåŠ¡ï¼ˆSyntax Analysis Serviceï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šå°†Tokenæµè½¬æ¢ä¸ºASTï¼Œå®ç°è¯­æ³•åˆ†æã€‚

```go
// SyntaxParser è¯­æ³•åˆ†æå™¨æ¥å£
type SyntaxParser interface {
    // Parse å°†Tokenåºåˆ—è§£æä¸ºAST
    Parse(tokens []Token) (*Program, error)
}

// RecursiveDescentParser é€’å½’ä¸‹é™è§£æå™¨
type RecursiveDescentParser struct {
    tokens []Token
    pos    int
}

func (p *RecursiveDescentParser) Parse(tokens []Token) (*Program, error) {
    p.tokens = tokens
    p.pos = 0

    program := &Program{}
    for !p.isAtEnd() {
        stmt, err := p.parseStatement()
        if err != nil {
            return nil, err
        }
        program.AddStatement(stmt)
    }

    return program, nil
}

// æ ¸å¿ƒè§£ææ–¹æ³•
func (p *RecursiveDescentParser) parseStatement() (Statement, error) {
    if p.match(Keyword, "func") {
        return p.parseFunctionDeclaration()
    }
    if p.match(Keyword, "let") {
        return p.parseVariableDeclaration()
    }
    if p.match(Keyword, "if") {
        return p.parseIfStatement()
    }
    // ... å…¶ä»–è¯­å¥ç±»å‹

    return nil, p.error("Expected statement")
}

// è¾…åŠ©æ–¹æ³•
func (p *RecursiveDescentParser) match(kind TokenKind, value string) bool {
    if p.check(kind, value) {
        p.advance()
        return true
    }
    return false
}

func (p *RecursiveDescentParser) check(kind TokenKind, value string) bool {
    if p.isAtEnd() {
        return false
    }
    token := p.peek()
    return token.Kind == kind && token.Value == value
}

func (p *RecursiveDescentParser) advance() Token {
    if !p.isAtEnd() {
        p.pos++
    }
    return p.previous()
}

func (p *RecursiveDescentParser) isAtEnd() bool {
    return p.pos >= len(p.tokens)
}

func (p *RecursiveDescentParser) peek() Token {
    return p.tokens[p.pos]
}

func (p *RecursiveDescentParser) previous() Token {
    return p.tokens[p.pos-1]
}
```

**è®¾è®¡å†³ç­–**ï¼š
- **é€’å½’ä¸‹é™**ï¼šé€‚åˆæ‰‹å†™è§£æå™¨ï¼Œæ˜“äºç†è§£å’Œç»´æŠ¤
- **é”™è¯¯æ¢å¤**ï¼šé‡åˆ°é”™è¯¯ç«‹å³åœæ­¢ï¼Œä¸å°è¯•ç»§ç»­è§£æ
- **ç»„åˆæ¨¡å¼**ï¼šè§£æå™¨ç»„åˆå¤šä¸ªå­è§£æå™¨

### 3. è¯­ä¹‰åˆ†ææœåŠ¡ï¼ˆSemantic Analysis Serviceï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šå¯¹ASTè¿›è¡Œè¯­ä¹‰åˆ†æï¼Œå»ºç«‹ç¬¦å·è¡¨ï¼Œè¿›è¡Œç±»å‹æ£€æŸ¥ã€‚

```go
// SemanticAnalyzer è¯­ä¹‰åˆ†æå™¨æ¥å£
type SemanticAnalyzer interface {
    // Analyze å¯¹ASTè¿›è¡Œè¯­ä¹‰åˆ†æ
    Analyze(program *Program) (SymbolTable, []SemanticError)
}

// ComprehensiveSemanticAnalyzer ç»¼åˆè¯­ä¹‰åˆ†æå™¨
type ComprehensiveSemanticAnalyzer struct {
    symbolResolver SymbolResolver
    typeChecker    TypeChecker
}

func (sa *ComprehensiveSemanticAnalyzer) Analyze(program *Program) (SymbolTable, []SemanticError) {
    var errors []SemanticError

    // ç¬¬ä¸€éï¼šæ”¶é›†ç¬¦å·å®šä¹‰
    symbolCollector := NewSymbolCollector()
    symbolTable, collectErrors := symbolCollector.Collect(program)
    errors = append(errors, collectErrors...)

    // ç¬¬äºŒéï¼šè§£æç¬¦å·å¼•ç”¨
    resolver := NewSymbolResolver(symbolTable)
    resolveErrors := resolver.Resolve(program)
    errors = append(errors, resolveErrors...)

    // ç¬¬ä¸‰éï¼šç±»å‹æ£€æŸ¥
    typeChecker := NewTypeChecker(symbolTable)
    typeErrors := typeChecker.Check(program)
    errors = append(errors, typeErrors...)

    return symbolTable, errors
}

// SymbolCollector ç¬¦å·æ”¶é›†å™¨
type SymbolCollector struct {
    symbolTable SymbolTable
    scopeStack  []*Scope
}

func (sc *SymbolCollector) Collect(program *Program) (SymbolTable, []SemanticError) {
    sc.symbolTable = NewSymbolTable()
    sc.scopeStack = []*Scope{sc.symbolTable.GlobalScope()}

    var errors []SemanticError
    for _, stmt := range program.Statements {
        if err := stmt.Accept(sc); err != nil {
            errors = append(errors, SemanticError{Message: err.Error()})
        }
    }

    return sc.symbolTable, errors
}

// è®¿é—®è€…æ¨¡å¼ï¼šæ”¶é›†ä¸åŒç±»å‹çš„ç¬¦å·
func (sc *SymbolCollector) VisitFunctionDeclaration(fd *FunctionDeclaration) error {
    symbol := &Symbol{
        Name:     fd.Name,
        Kind:     FunctionSymbol,
        Type:     fd.Signature,
        Position: fd.Position,
    }
    return sc.currentScope().DefineSymbol(symbol)
}

func (sc *SymbolCollector) VisitVariableDeclaration(vd *VariableDeclaration) error {
    symbol := &Symbol{
        Name:     vd.Name,
        Kind:     VariableSymbol,
        Type:     vd.Type,
        Position: vd.Position,
    }
    return sc.currentScope().DefineSymbol(symbol)
}
```

**è®¾è®¡å†³ç­–**ï¼š
- **å¤šéåˆ†æ**ï¼šåˆ†é˜¶æ®µè¿›è¡Œç¬¦å·æ”¶é›†ã€å¼•ç”¨è§£æã€ç±»å‹æ£€æŸ¥
- **è®¿é—®è€…æ¨¡å¼**ï¼šè§£è€¦åˆ†æé€»è¾‘å’ŒASTèŠ‚ç‚¹ç±»å‹
- **é”™è¯¯æ”¶é›†**ï¼šä¸å› å•ä¸ªé”™è¯¯åœæ­¢åˆ†æï¼Œæ”¶é›†æ‰€æœ‰é”™è¯¯

### 4. ç¬¦å·è§£ææœåŠ¡ï¼ˆSymbol Resolution Serviceï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šæä¾›ç¬¦å·æŸ¥æ‰¾å’Œè§£æåŠŸèƒ½ï¼Œæ”¯æŒä½œç”¨åŸŸç®¡ç†ã€‚

```go
// SymbolResolver ç¬¦å·è§£æå™¨æ¥å£
type SymbolResolver interface {
    // ResolveSymbol åœ¨ä½œç”¨åŸŸé“¾ä¸­æŸ¥æ‰¾ç¬¦å·
    ResolveSymbol(name string, scope *Scope) (*Symbol, error)

    // CreateScope åˆ›å»ºæ–°çš„ä½œç”¨åŸŸ
    CreateScope(parent *Scope, kind ScopeKind) *Scope

    // EnterScope è¿›å…¥ä½œç”¨åŸŸ
    EnterScope(scope *Scope)

    // ExitScope é€€å‡ºä½œç”¨åŸŸ
    ExitScope()
}

// DefaultSymbolResolver é»˜è®¤ç¬¦å·è§£æå™¨
type DefaultSymbolResolver struct {
    currentScope *Scope
    scopeStack   []*Scope
}

func (sr *DefaultSymbolResolver) ResolveSymbol(name string, scope *Scope) (*Symbol, error) {
    current := scope
    for current != nil {
        if symbol, exists := current.Symbols[name]; exists {
            return symbol, nil
        }
        current = current.Parent
    }
    return nil, fmt.Errorf("undefined symbol: %s", name)
}

func (sr *DefaultSymbolResolver) CreateScope(parent *Scope, kind ScopeKind) *Scope {
    return &Scope{
        ID:      generateID(),
        Parent:  parent,
        Symbols: make(map[string]*Symbol),
        Kind:    kind,
    }
}

func (sr *DefaultSymbolResolver) EnterScope(scope *Scope) {
    sr.scopeStack = append(sr.scopeStack, sr.currentScope)
    sr.currentScope = scope
}

func (sr *DefaultSymbolResolver) ExitScope() {
    if len(sr.scopeStack) > 0 {
        sr.currentScope = sr.scopeStack[len(sr.scopeStack)-1]
        sr.scopeStack = sr.scopeStack[:len(sr.scopeStack)-1]
    }
}
```

### 5. ç±»å‹æ£€æŸ¥æœåŠ¡ï¼ˆType Checking Serviceï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šéªŒè¯è¡¨è¾¾å¼çš„ç±»å‹æ­£ç¡®æ€§ï¼Œç¡®ä¿ç±»å‹å®‰å…¨ã€‚

```go
// TypeChecker ç±»å‹æ£€æŸ¥å™¨æ¥å£
type TypeChecker interface {
    // Check å¯¹ç¨‹åºè¿›è¡Œç±»å‹æ£€æŸ¥
    Check(program *Program) []TypeError

    // CheckExpression æ£€æŸ¥è¡¨è¾¾å¼çš„ç±»å‹
    CheckExpression(expr Expression, symbolTable SymbolTable) (Type, error)

    // CheckStatement æ£€æŸ¥è¯­å¥çš„ç±»å‹
    CheckStatement(stmt Statement, symbolTable SymbolTable) error
}

// ComprehensiveTypeChecker ç»¼åˆç±»å‹æ£€æŸ¥å™¨
type ComprehensiveTypeChecker struct {
    symbolTable SymbolTable
}

func (tc *ComprehensiveTypeChecker) Check(program *Program) []TypeError {
    var errors []TypeError

    for _, stmt := range program.Statements {
        if err := tc.CheckStatement(stmt, tc.symbolTable); err != nil {
            errors = append(errors, TypeError{Message: err.Error()})
        }
    }

    return errors
}

func (tc *ComprehensiveTypeChecker) CheckExpression(expr Expression, symbolTable SymbolTable) (Type, error) {
    switch e := expr.(type) {
    case *BinaryExpression:
        return tc.checkBinaryExpression(e, symbolTable)
    case *FunctionCall:
        return tc.checkFunctionCall(e, symbolTable)
    case *Identifier:
        return tc.checkIdentifier(e, symbolTable)
    case *Literal:
        return tc.checkLiteral(e, symbolTable)
    default:
        return Type{}, fmt.Errorf("unknown expression type: %T", expr)
    }
}

func (tc *ComprehensiveTypeChecker) checkBinaryExpression(expr *BinaryExpression, symbolTable SymbolTable) (Type, error) {
    leftType, err := tc.CheckExpression(expr.Left, symbolTable)
    if err != nil {
        return Type{}, err
    }

    rightType, err := tc.CheckExpression(expr.Right, symbolTable)
    if err != nil {
        return Type{}, err
    }

    // ç±»å‹å…¼å®¹æ€§æ£€æŸ¥
    if !tc.areTypesCompatible(leftType, rightType, expr.Operator) {
        return Type{}, fmt.Errorf("incompatible types for operator %s: %s and %s",
            expr.Operator, leftType.Name, rightType.Name)
    }

    // è¿”å›ç»“æœç±»å‹
    return tc.getResultType(leftType, rightType, expr.Operator), nil
}

func (tc *ComprehensiveTypeChecker) areTypesCompatible(left, right Type, operator string) bool {
    // ç®—æœ¯è¿ç®—ç¬¦
    if operator == "+" || operator == "-" || operator == "*" || operator == "/" {
        return (left.IsNumeric() && right.IsNumeric()) ||
               (left.Name == "string" && right.Name == "string" && operator == "+")
    }

    // æ¯”è¾ƒè¿ç®—ç¬¦
    if operator == "==" || operator == "!=" || operator == "<" || operator == ">" {
        return left.Equals(right) || (left.IsNumeric() && right.IsNumeric())
    }

    return false
}
```

## ğŸ—„ï¸ ä»“å‚¨æ¥å£è®¾è®¡

### 1. æºæ–‡ä»¶ä»“å‚¨ï¼ˆSourceFile Repositoryï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šç®¡ç†æºæ–‡ä»¶çš„æŒä¹…åŒ–ï¼Œæä¾›æŒ‰è·¯å¾„å’ŒIDæŸ¥æ‰¾åŠŸèƒ½ã€‚

```go
// SourceFileRepository æºæ–‡ä»¶ä»“å‚¨æ¥å£
type SourceFileRepository interface {
    // Save ä¿å­˜æºæ–‡ä»¶
    Save(file *SourceFile) error

    // FindByID æŒ‰IDæŸ¥æ‰¾æºæ–‡ä»¶
    FindByID(id string) (*SourceFile, error)

    // FindByPath æŒ‰è·¯å¾„æŸ¥æ‰¾æºæ–‡ä»¶
    FindByPath(path string) (*SourceFile, error)

    // FindAll è·å–æ‰€æœ‰æºæ–‡ä»¶
    FindAll() ([]*SourceFile, error)

    // Delete åˆ é™¤æºæ–‡ä»¶
    Delete(id string) error

    // Exists æ£€æŸ¥æºæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    Exists(id string) bool
}
```

**è®¾è®¡å†³ç­–**ï¼š
- **æŒ‰èšåˆæ ¹è®¾è®¡**ï¼šå›´ç»•SourceFileèšåˆæ ¹æä¾›æ“ä½œ
- **æŸ¥è¯¢æ–¹æ³•ä¸°å¯Œ**ï¼šæ”¯æŒæŒ‰IDã€è·¯å¾„ç­‰å¤šç§æŸ¥è¯¢æ–¹å¼
- **ä¸šåŠ¡è¯­ä¹‰**ï¼šæ–¹æ³•ååæ˜ ä¸šåŠ¡æ„å›¾

### 2. ç¬¦å·ä»“å‚¨ï¼ˆSymbol Repositoryï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šç®¡ç†ç¬¦å·çš„æŒä¹…åŒ–ï¼Œæ”¯æŒç¬¦å·çš„å®šä¹‰å’ŒæŸ¥æ‰¾ã€‚

```go
// SymbolRepository ç¬¦å·ä»“å‚¨æ¥å£
type SymbolRepository interface {
    // Save ä¿å­˜ç¬¦å·
    Save(symbol *Symbol) error

    // FindByID æŒ‰IDæŸ¥æ‰¾ç¬¦å·
    FindByID(id string) (*Symbol, error)

    // FindByNameAndScope åœ¨æŒ‡å®šä½œç”¨åŸŸä¸­æŒ‰åç§°æŸ¥æ‰¾ç¬¦å·
    FindByNameAndScope(name string, scopeID string) (*Symbol, error)

    // FindAllInScope æŸ¥æ‰¾ä½œç”¨åŸŸä¸­çš„æ‰€æœ‰ç¬¦å·
    FindAllInScope(scopeID string) ([]*Symbol, error)

    // FindAllInFile æŸ¥æ‰¾æ–‡ä»¶ä¸­æ‰€æœ‰ç¬¦å·
    FindAllInFile(fileID string) ([]*Symbol, error)

    // UpdateType æ›´æ–°ç¬¦å·ç±»å‹
    UpdateType(symbolID string, newType Type) error

    // Delete åˆ é™¤ç¬¦å·
    Delete(id string) error
}
```

**è®¾è®¡å†³ç­–**ï¼š
- **ä½œç”¨åŸŸæ„ŸçŸ¥**ï¼šæ”¯æŒæŒ‰ä½œç”¨åŸŸæŸ¥è¯¢ç¬¦å·
- **ç±»å‹æ›´æ–°**ï¼šæ”¯æŒç¬¦å·ç±»å‹çš„åŠ¨æ€æ›´æ–°
- **æ‰¹é‡æŸ¥è¯¢**ï¼šæ”¯æŒä½œç”¨åŸŸå’Œæ–‡ä»¶çš„æ‰¹é‡æŸ¥è¯¢

### 3. ç¨‹åºä»“å‚¨ï¼ˆProgram Repositoryï¼‰

**ä¸šåŠ¡èŒè´£**ï¼šç®¡ç†ASTçš„æŒä¹…åŒ–ï¼Œæ”¯æŒç¨‹åºç»“æ„çš„å­˜å‚¨å’ŒæŸ¥è¯¢ã€‚

```go
// ProgramRepository ç¨‹åºä»“å‚¨æ¥å£
type ProgramRepository interface {
    // Save ä¿å­˜ç¨‹åºAST
    Save(program *Program) error

    // FindByID æŒ‰IDæŸ¥æ‰¾ç¨‹åº
    FindByID(id string) (*Program, error)

    // FindBySourceFile æŸ¥æ‰¾æºæ–‡ä»¶çš„ç¨‹åº
    FindBySourceFile(sourceFileID string) (*Program, error)

    // UpdateStatements æ›´æ–°ç¨‹åºè¯­å¥
    UpdateStatements(programID string, statements []Statement) error

    // Delete åˆ é™¤ç¨‹åº
    Delete(id string) error
}
```

## ğŸ¯ æœåŠ¡åä½œè®¾è®¡

### åº”ç”¨æœåŠ¡ç¼–æ’

```go
// FrontendAnalysisService åº”ç”¨æœåŠ¡ï¼šç¼–æ’åˆ†ææµç¨‹
type FrontendAnalysisService struct {
    tokenizer        Tokenizer
    syntaxParser     SyntaxParser
    semanticAnalyzer SemanticAnalyzer
    sourceFileRepo   SourceFileRepository
}

func (s *FrontendAnalysisService) AnalyzeSourceFile(filePath string) (*AnalysisResult, error) {
    // 1. åŠ è½½æˆ–åˆ›å»ºæºæ–‡ä»¶
    sourceFile, err := s.sourceFileRepo.FindByPath(filePath)
    if err != nil {
        // åˆ›å»ºæ–°æºæ–‡ä»¶
        content, err := ioutil.ReadFile(filePath)
        if err != nil {
            return nil, err
        }
        sourceFile = &SourceFile{
            ID:      generateID(),
            Path:    filePath,
            Content: string(content),
            Status:  Created,
        }
    }

    // 2. è¯æ³•åˆ†æ
    if err := sourceFile.Tokenize(s.tokenizer); err != nil {
        return nil, err
    }

    // 3. è¯­æ³•åˆ†æ
    if err := sourceFile.Parse(s.syntaxParser); err != nil {
        return nil, err
    }

    // 4. è¯­ä¹‰åˆ†æ
    if err := sourceFile.Analyze(s.semanticAnalyzer); err != nil {
        return nil, err
    }

    // 5. ä¿å­˜ç»“æœ
    if err := s.sourceFileRepo.Save(sourceFile); err != nil {
        return nil, err
    }

    return &AnalysisResult{
        SourceFile: sourceFile,
        Success:    len(sourceFile.Diagnostics) == 0,
    }, nil
}
```

### ä¾èµ–æ³¨å…¥é…ç½®

```go
// DIé…ç½®ï¼šè¿æ¥æ‰€æœ‰æœåŠ¡
func BuildFrontendServices() *FrontendServices {
    return &FrontendServices{
        Tokenizer:        &SimpleTokenizer{},
        SyntaxParser:     &RecursiveDescentParser{},
        SemanticAnalyzer: &ComprehensiveSemanticAnalyzer{
            SymbolResolver: &DefaultSymbolResolver{},
            TypeChecker:    &ComprehensiveTypeChecker{},
        },
        SourceFileRepo:   &InMemorySourceFileRepository{},
        SymbolRepo:       &InMemorySymbolRepository{},
        ProgramRepo:      &InMemoryProgramRepository{},
    }
}
```

## ğŸ“ˆ è®¾è®¡è´¨é‡è¯„ä¼°

### èŒè´£åˆ†ç¦»
- âœ… **Tokenizer**ï¼šåªè´Ÿè´£è¯æ³•åˆ†æ
- âœ… **SyntaxParser**ï¼šåªè´Ÿè´£è¯­æ³•åˆ†æ
- âœ… **SemanticAnalyzer**ï¼šåªè´Ÿè´£è¯­ä¹‰åˆ†æ
- âœ… **TypeChecker**ï¼šåªè´Ÿè´£ç±»å‹æ£€æŸ¥
- âœ… **SymbolResolver**ï¼šåªè´Ÿè´£ç¬¦å·è§£æ

### æ¥å£éš”ç¦»
- âœ… **ä¾èµ–å€’ç½®**ï¼šåº”ç”¨å±‚ä¾èµ–é¢†åŸŸæœåŠ¡æ¥å£
- âœ… **å•ä¸€èŒè´£**ï¼šæ¯ä¸ªæ¥å£èŒè´£æ˜ç¡®
- âœ… **æ˜“äºæµ‹è¯•**ï¼šæ¥å£å¯è½»æ¾Mock

### ä¸šåŠ¡è¡¨è¾¾åŠ›
- âœ… **æ–¹æ³•å‘½å**ï¼šTokenizeã€Parseã€Analyzeç­‰ç›´æ¥åæ˜ ä¸šåŠ¡æ„å›¾
- âœ… **é”™è¯¯å¤„ç†**ï¼šé”™è¯¯ä¿¡æ¯ä½¿ç”¨ä¸šåŠ¡è¯­è¨€
- âœ… **ç±»å‹å®‰å…¨**ï¼šå¼ºç±»å‹ç¡®ä¿ç¼–è¯‘æ—¶æ£€æŸ¥

### å¯æ‰©å±•æ€§
- âœ… **æ–°åˆ†æå™¨**ï¼šå¯è½»æ¾æ·»åŠ æ–°çš„åˆ†æé˜¶æ®µ
- âœ… **æ–°è¯­æ³•**ï¼šé€šè¿‡æ‰©å±•Parseræ¥å£æ”¯æŒ
- âœ… **æ–°ç±»å‹**ï¼šé€šè¿‡æ‰©å±•Typeç³»ç»Ÿæ”¯æŒ
